"""
Whisper AVAN√áADO - Vers√£o Final com Todas as Melhorias
Implementa:
- Diariza√ß√£o separada (PyAnnote antes do Whisper)
- Segmenta√ß√£o por t√≥picos com palavras-chave
- Limpeza de v√≠cios de fala
- Normaliza√ß√£o robusta de termos
- P√≥s-corre√ß√£o sem√¢ntica (opcional com LLM)
- Organiza√ß√£o em blocos tem√°ticos estruturados
"""
import whisper
import os
import sys
import time
import torch
import re
import json
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple
import warnings
warnings.filterwarnings("ignore")

# Tenta importar PyAnnote (opcional)
try:
    from pyannote.audio import Pipeline
    PYANNOTE_AVAILABLE = True
except ImportError:
    PYANNOTE_AVAILABLE = False
    print("‚ö†Ô∏è  PyAnnote n√£o dispon√≠vel. Usando diariza√ß√£o simplificada.")

# ============================================================================
# CONFIGURA√á√ïES
# ============================================================================

# Gloss√°rio de termos t√©cnicos
GLOSSARIO_TERMOS = [
    "pitch", "MVP", "Storytelling", "Impulsione", 
    "call to action", "ROI", "payback",
    "prontu√°rio", "fluxograma", "slides",
    "ChatGPT", "prot√≥tipo", "valida√ß√£o",
    "piloto", "cooperativa", "Unimed",
    "banca", "mentoria", "pre-pitch",
    "Distrito 28", "hub", "SIAC", "IBAMA", "IFS"
]

# Normaliza√ß√£o de termos (corre√ß√µes mais robustas)
NORMALIZACAO_TERMOS = {
    "pitch": ["bit", "pitt", "pit", "PIT", "PTIP", "pichi", "pitchi"],
    "ChatGPT": ["chat IPT", "chat ipt", "chatGPT", "chat gpt"],
    "slides": ["exides", "exide", "slids"],
    "Storytelling": ["story t√©lia", "story tell", "storytel", "story telling"],
    "Impulsione": ["Impulsionian", "impulsione", "impusione"],
    "fluxograma": ["fluxo-grama", "fluxo grama"],
    "prontu√°rio": ["pronto arim√©trico", "prontu√°rio eletr√¥nico"],
    "prot√≥tipo": ["prototipo", "prot√≥tipo"],
    "Sharks": ["Ch√°x", "Shark"],
    "Shark Tank": ["Shark Ten", "Shark Tank"],
    "pre-pitch": ["prepitch", "prepit", "pre-pitch"],
    "mentoria": ["mentories", "mentorie"],
    "capilar": ["capital√°"],
    "frizz": ["fris"],
    "Anel√≠cia Libardoni": ["Anulet√≠cia Libardo"],
}

# V√≠cios de fala para remover/limpar
VICIOS_FALA = [
    r'\bn√©\b',
    r'\bt√°\b',
    r'\benfim\b',
    r'\be\.\.\.\b',
    r'\bent√£o\.\.\.\b',
    r'\bassim\.\.\.\b',
    r'\bn√©\?\s*',
    r'\bt√°\?\s*',
    r'\bn√©\s*',
    r'\bt√°\s*',
]

# Palavras-chave para segmenta√ß√£o por t√≥picos
TOPICOS_KEYWORDS = {
    "Apresenta√ß√£o": ["apresenta√ß√£o", "capa", "logo", "slogan", "primeiro slide"],
    "Problema": ["problema", "dor", "hist√≥ria", "storytelling", "valida√ß√£o", "dados", "pesquisa"],
    "Solu√ß√£o": ["solu√ß√£o", "prot√≥tipo", "fluxo", "funcionalidade", "aplicativo", "sistema"],
    "Benef√≠cios": ["benef√≠cios", "resultados", "impacto", "m√©trica", "indicador"],
    "Diferencial": ["diferencial", "comparativo", "processo atual", "ganho"],
    "Time": ["time", "equipe", "membros", "compet√™ncias", "especialista"],
    "Pr√≥ximos Passos": ["pr√≥ximos passos", "plano", "implementa√ß√£o", "cronograma", "riscos", "investimento", "recursos"],
    "Call to Action": ["call to action", "chamada para a√ß√£o", "voc√™", "invista", "revolucionar"],
    "Avalia√ß√£o": ["banca avaliadora", "banca", "avaliar", "observar", "pontuar", "perguntas frequentes"],
    "Regras": ["regras", "presen√ßa", "engajamento", "mentoria", "planilha", "prazo", "dia 18"],
    "Exemplo": ["Shark Tank", "Shark Ten", "exemplo", "v√≠deo", "Solta Beauty"],
    "Log√≠stica": ["pre-pitch", "Distrito 28", "hub", "hor√°rio", "local", "presencial", "online"],
    "Finaliza√ß√£o": ["m√∫sica", "foto", "lista de presen√ßa", "QR Code", "encerrar"]
}

# ============================================================================
# FUN√á√ïES AUXILIARES
# ============================================================================

def formatar_timestamp(segundos):
    """Converte segundos em formato HH:MM:SS"""
    return str(timedelta(seconds=int(segundos)))

def extrair_audio_segmento(audio_file: str, inicio: float, fim: float, output_file: str):
    """
    Extrai segmento de √°udio (requer ffmpeg)
    """
    import subprocess
    try:
        cmd = [
            'ffmpeg', '-i', audio_file,
            '-ss', str(inicio),
            '-t', str(fim - inicio),
            '-acodec', 'copy',
            output_file,
            '-y', '-loglevel', 'quiet'
        ]
        result = subprocess.run(cmd, check=True, capture_output=True, text=True)
        return os.path.exists(output_file)
    except subprocess.CalledProcessError as e:
        print(f"‚ö†Ô∏è  Erro ao extrair segmento: {e}")
        return False
    except FileNotFoundError:
        print("‚ö†Ô∏è  ffmpeg n√£o encontrado. Instale ffmpeg para usar diariza√ß√£o com PyAnnote.")
        return False
    except Exception as e:
        print(f"‚ö†Ô∏è  Erro ao extrair segmento: {e}")
        return False

# ============================================================================
# DIARIZA√á√ÉO SEPARADA (PyAnnote)
# ============================================================================

def diarizar_com_pyannote(audio_file: str, auth_token: Optional[str] = None):
    """
    Diariza√ß√£o usando PyAnnote (antes do Whisper)
    Retorna lista de segmentos com speaker e timestamps
    """
    if not PYANNOTE_AVAILABLE:
        return None
    
    try:
        print("üîç Iniciando diariza√ß√£o com PyAnnote...")
        
        # Carrega pipeline de diariza√ß√£o
        if auth_token:
            pipeline = Pipeline.from_pretrained(
                "pyannote/speaker-diarization-3.1",
                use_auth_token=auth_token
            )
        else:
            # Tenta carregar sem token (pode n√£o funcionar)
            try:
                pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization-3.1")
            except:
                print("‚ö†Ô∏è  PyAnnote requer token de autentica√ß√£o. Use diariza√ß√£o simplificada.")
                return None
        
        # Executa diariza√ß√£o
        diarization = pipeline(audio_file)
        
        # Converte para formato simples
        segmentos = []
        for turn, _, speaker in diarization.itertracks(yield_label=True):
            segmentos.append({
                'start': turn.start,
                'end': turn.end,
                'speaker': speaker
            })
        
        print(f"‚úì Diariza√ß√£o conclu√≠da: {len(segmentos)} segmentos, {len(set(s['speaker'] for s in segmentos))} speakers")
        return segmentos
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Erro na diariza√ß√£o PyAnnote: {e}")
        print("   Usando diariza√ß√£o simplificada...")
        return None

# ============================================================================
# NORMALIZA√á√ÉO DE TERMOS
# ============================================================================

def normalizar_termos(texto: str) -> str:
    """
    Normaliza termos t√©cnicos usando dicion√°rio robusto
    """
    texto_normalizado = texto
    
    for termo_correto, variacoes in NORMALIZACAO_TERMOS.items():
        for variacao in variacoes:
            # Busca palavra completa (n√£o substring)
            pattern = r'\b' + re.escape(variacao) + r'\b'
            texto_normalizado = re.sub(pattern, termo_correto, texto_normalizado, flags=re.IGNORECASE)
    
    return texto_normalizado

# ============================================================================
# LIMPEZA DE V√çCIOS DE FALA
# ============================================================================

def limpar_vicios_fala(texto: str, modo: str = "medio") -> str:
    """
    Remove ou limpa v√≠cios de fala comuns
    
    Modos:
    - "leve": Remove apenas repeti√ß√µes excessivas
    - "medio": Remove v√≠cios comuns (n√©, t√°, enfim) ‚≠ê RECOMENDADO
    - "agressivo": Remove todos os v√≠cios + ajustes de fluidez
    """
    texto_limpo = texto
    
    if modo == "leve":
        # Remove apenas repeti√ß√µes
        texto_limpo = re.sub(r'\.\.\.+', '...', texto_limpo)
        texto_limpo = re.sub(r'\s+', ' ', texto_limpo)
    
    elif modo == "medio":
        # Remove v√≠cios comuns
        for vicio in VICIOS_FALA:
            texto_limpo = re.sub(vicio, '', texto_limpo, flags=re.IGNORECASE)
        # Limpa espa√ßos duplos
        texto_limpo = re.sub(r'\s+', ' ', texto_limpo)
        # Remove v√≠rgulas duplas
        texto_limpo = re.sub(r',\s*,', ',', texto_limpo)
    
    elif modo == "agressivo":
        # Remove todos os v√≠cios
        for vicio in VICIOS_FALA:
            texto_limpo = re.sub(vicio, '', texto_limpo, flags=re.IGNORECASE)
        # Ajustes de fluidez
        texto_limpo = re.sub(r'\s+', ' ', texto_limpo)
        texto_limpo = re.sub(r'([.!?])\1+', r'\1', texto_limpo)
        texto_limpo = re.sub(r'([.!?])([A-Za-z])', r'\1 \2', texto_limpo)
        texto_limpo = re.sub(r'\s+([,.!?;:])', r'\1', texto_limpo)
    
    return texto_limpo.strip()

# ============================================================================
# SEGMENTA√á√ÉO POR T√ìPICOS
# ============================================================================

def identificar_topico(texto: str) -> Optional[str]:
    """
    Identifica t√≥pico baseado em palavras-chave
    """
    texto_lower = texto.lower()
    
    # Conta matches por t√≥pico
    scores = {}
    for topico, keywords in TOPICOS_KEYWORDS.items():
        score = sum(1 for kw in keywords if kw.lower() in texto_lower)
        if score > 0:
            scores[topico] = score
    
    if scores:
        # Retorna t√≥pico com maior score
        return max(scores.items(), key=lambda x: x[1])[0]
    
    return None

def segmentar_por_topicos(segmentos: List[Dict], max_chars: int = 600) -> List[Dict]:
    """
    Segmenta transcri√ß√£o por t√≥picos e tamanho de bloco
    """
    segmentos_organizados = []
    topico_atual = None
    
    for seg in segmentos:
        texto = seg.get('text', '')
        topico = identificar_topico(texto)
        
        # Se mudou t√≥pico ou bloco muito grande, cria novo segmento
        if topico and topico != topico_atual:
            topico_atual = topico
            seg['topico'] = topico
        elif len(texto) > max_chars and topico_atual:
            # Divide bloco grande
            seg['topico'] = topico_atual
        else:
            seg['topico'] = topico_atual or "Geral"
        
        segmentos_organizados.append(seg)
    
    return segmentos_organizados

# ============================================================================
# P√ìS-CORRE√á√ÉO SEM√ÇNTICA (LLM)
# ============================================================================

def corrigir_com_llm(texto: str, api_key: Optional[str] = None, modelo: str = "gpt-3.5-turbo") -> str:
    """
    P√≥s-corre√ß√£o sem√¢ntica usando LLM (opcional)
    Requer API key do OpenAI ou outro provedor
    """
    if not api_key:
        return texto  # Retorna original se n√£o tiver API key
    
    try:
        import openai
        openai.api_key = api_key
        
        prompt = f"""Limpe e corrija a transcri√ß√£o abaixo:

- Corrija concord√¢ncia e gram√°tica
- Retire v√≠cios de fala ("n√©", "t√°", "enfim") apenas se n√£o afetar o sentido
- Mantenha o sentido original
- N√ÉO resuma
- Melhore fluidez e clareza
- Mantenha termos t√©cnicos (pitch, MVP, Storytelling, etc.)

Texto:
{texto}

Texto corrigido:"""
        
        response = openai.ChatCompletion.create(
            model=modelo,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=len(texto.split()) * 2
        )
        
        return response.choices[0].message.content.strip()
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Erro na corre√ß√£o LLM: {e}")
        return texto

# ============================================================================
# ETAPA 1: TRANSCRI√á√ÉO (SOMENTE TRANSCREVE, SEM CORRE√á√ïES)
# ============================================================================

def transcrever_apenas(caminho_video: str,
                      modelo: str = "large-v3",
                      usar_pyannote: bool = True,
                      pyannote_token: Optional[str] = None):
    """
    ETAPA 1: Apenas transcreve o v√≠deo e salva resultado bruto
    N√£o aplica corre√ß√µes - isso fica para a etapa 2
    """
    print("="*70)
    print("üìù ETAPA 1: TRANSCRI√á√ÉO (SEM CORRE√á√ïES)")
    print("="*70)
    print()
    
    if not os.path.exists(caminho_video):
        print(f"‚ùå Arquivo n√£o encontrado: {caminho_video}")
        return None
    
    tamanho_mb = os.path.getsize(caminho_video) / (1024 * 1024)
    print(f"üìÅ Arquivo: {os.path.basename(caminho_video)}")
    print(f"üìä Tamanho: {tamanho_mb:.2f} MB")
    
    tem_gpu = torch.cuda.is_available()
    if tem_gpu:
        print(f"‚úì GPU: {torch.cuda.get_device_name(0)}")
    else:
        print("‚ö†Ô∏è  CPU (ser√° mais lento)")
    
    print(f"ü§ñ Modelo: {modelo}")
    print(f"üé§ PyAnnote: {'Sim' if usar_pyannote and PYANNOTE_AVAILABLE else 'N√£o'}")
    print()
    
    try:
        # PASSO 1: Diariza√ß√£o (se dispon√≠vel)
        segmentos_diarizacao = None
        if usar_pyannote and PYANNOTE_AVAILABLE:
            segmentos_diarizacao = diarizar_com_pyannote(caminho_video, pyannote_token)
        
        # PASSO 2: Carrega modelo Whisper
        print("üì• Carregando modelo Whisper...")
        inicio_carga = time.time()
        
        try:
            model = whisper.load_model(modelo)
        except Exception:
            if modelo == "large-v3":
                print("‚ö†Ô∏è  large-v3 n√£o dispon√≠vel, usando large")
                model = whisper.load_model("large")
            else:
                raise
        
        tempo_carga = time.time() - inicio_carga
        print(f"‚úì Modelo carregado em {tempo_carga:.1f}s")
        print()
        
        # PASSO 3: Transcri√ß√£o (SEM corre√ß√µes)
        segmentos_transcritos = []
        
        if segmentos_diarizacao:
            # Transcreve por segmento diarizado
            print("üéôÔ∏è  Transcrevendo por segmentos diarizados...")
            
            for i, seg_dia in enumerate(segmentos_diarizacao):
                print(f"   Segmento {i+1}/{len(segmentos_diarizacao)}: {formatar_timestamp(seg_dia['start'])} - {formatar_timestamp(seg_dia['end'])}")
                
                # Extrai √°udio do segmento
                temp_audio = f"temp_segment_{i}.wav"
                if extrair_audio_segmento(caminho_video, seg_dia['start'], seg_dia['end'], temp_audio):
                    # Transcreve segmento
                    resultado = model.transcribe(
                        temp_audio,
                        language='pt',
                        task='transcribe',
                        fp16=tem_gpu,
                        word_timestamps=True,
                        initial_prompt=" ".join(GLOSSARIO_TERMOS[:20])
                    )
                    
                    texto = resultado.get('text', '').strip()
                    if texto:
                        segmentos_transcritos.append({
                            'start': seg_dia['start'],
                            'end': seg_dia['end'],
                            'speaker': seg_dia['speaker'],
                            'text': texto
                        })
                    
                    # Remove arquivo tempor√°rio
                    if os.path.exists(temp_audio):
                        os.remove(temp_audio)
            
            print(f"‚úì Transcri√ß√£o conclu√≠da: {len(segmentos_transcritos)} segmentos")
        else:
            # Transcri√ß√£o tradicional (sem diariza√ß√£o separada)
            print("üéôÔ∏è  Transcrevendo (m√©todo tradicional)...")
            inicio = time.time()
            
            resultado = model.transcribe(
                caminho_video,
                language='pt',
                task='transcribe',
                fp16=tem_gpu,
                verbose=True,
                word_timestamps=True,
                condition_on_previous_text=True,
                temperature=0.0,
                beam_size=5,
                best_of=5,
                initial_prompt=" ".join(GLOSSARIO_TERMOS[:20])
            )
            
            tempo_total = time.time() - inicio
            print(f"‚úì Transcri√ß√£o conclu√≠da em {tempo_total/60:.1f} min")
            
            # Converte segments para formato padr√£o
            segments = resultado.get('segments', [])
            speaker_atual = 1
            
            for seg in segments:
                segmentos_transcritos.append({
                    'start': seg['start'],
                    'end': seg['end'],
                    'speaker': f'Speaker {speaker_atual}',
                    'text': seg['text'].strip()
                })
                # Detecta mudan√ßa de speaker (simplificado)
                if len(segmentos_transcritos) > 1:
                    pausa = seg['start'] - segments[segments.index(seg)-1]['end']
                    if pausa > 2.5:
                        speaker_atual += 1
                        segmentos_transcritos[-1]['speaker'] = f'Speaker {speaker_atual}'
        
        # PASSO 4: Salva transcri√ß√£o BRUTA (sem corre√ß√µes)
        nome_base = Path(caminho_video).stem
        arquivo_bruto = f"{nome_base}_transcricao_bruta.txt"
        
        with open(arquivo_bruto, 'w', encoding='utf-8') as f:
            f.write("="*70 + "\n")
            f.write("üìù TRANSCRI√á√ÉO BRUTA (SEM CORRE√á√ïES)\n")
            f.write("="*70 + "\n\n")
            f.write(f"üìÅ Arquivo: {os.path.basename(caminho_video)}\n")
            f.write(f"ü§ñ Modelo: {modelo}\n")
            f.write(f"üé§ PyAnnote: {'Sim' if usar_pyannote and PYANNOTE_AVAILABLE else 'N√£o'}\n")
            f.write(f"üìä Segmentos: {len(segmentos_transcritos)}\n")
            f.write(f"üé§ Speakers: {len(set(s['speaker'] for s in segmentos_transcritos))}\n")
            f.write("\n" + "="*70 + "\n")
            f.write("TRANSCRI√á√ÉO BRUTA\n")
            f.write("="*70 + "\n\n")
            
            speaker_anterior = None
            for seg in segmentos_transcritos:
                if speaker_anterior and speaker_anterior != seg['speaker']:
                    f.write("\n")
                
                timestamp = formatar_timestamp(seg['start'])
                f.write(f"[{timestamp}] {seg['speaker']}:\n")
                f.write(f"{seg['text']}\n\n")
                
                speaker_anterior = seg['speaker']
        
        print("\n" + "="*70)
        print("‚úÖ ETAPA 1 CONCLU√çDA")
        print("="*70)
        print(f"üìÑ Arquivo bruto salvo: {arquivo_bruto}")
        print(f"üìä Segmentos: {len(segmentos_transcritos)}")
        print(f"üé§ Speakers: {len(set(s['speaker'] for s in segmentos_transcritos))}")
        print("\nüí° Pr√≥ximo passo: Execute a corre√ß√£o com:")
        print(f"   python whisper_avancado.py --corrigir \"{arquivo_bruto}\"")
        print("="*70)
        
        return {
            'arquivo_bruto': arquivo_bruto,
            'segmentos': segmentos_transcritos
        }
        
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Transcri√ß√£o cancelada")
        return None
    except Exception as e:
        print(f"\n‚ùå Erro: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

# ============================================================================
# ETAPA 2: CORRE√á√ÉO E ORGANIZA√á√ÉO (APLICA MELHORIAS)
# ============================================================================

def corrigir_e_organizar(caminho_arquivo_bruto: str,
                         modo_limpeza: str = "medio",
                         usar_llm: bool = False,
                         llm_api_key: Optional[str] = None,
                         max_chars_bloco: int = 600):
    """
    ETAPA 2: Aplica corre√ß√µes e organiza transcri√ß√£o bruta
    L√™ arquivo bruto e aplica todas as melhorias
    """
    print("="*70)
    print("üîß ETAPA 2: CORRE√á√ÉO E ORGANIZA√á√ÉO")
    print("="*70)
    print()
    
    if not os.path.exists(caminho_arquivo_bruto):
        print(f"‚ùå Arquivo n√£o encontrado: {caminho_arquivo_bruto}")
        return None
    
    print(f"üìÅ Arquivo bruto: {os.path.basename(caminho_arquivo_bruto)}")
    print(f"üîß Modo limpeza: {modo_limpeza}")
    print(f"ü§ñ LLM: {'Sim' if usar_llm else 'N√£o'}")
    print()
    
    # L√™ arquivo bruto
    print("üìñ Lendo transcri√ß√£o bruta...")
    segmentos = extrair_segmentos_do_arquivo_bruto(caminho_arquivo_bruto)
    print(f"‚úì {len(segmentos)} segmentos carregados")
    
    # Aplica melhorias
    print("\nüîß Aplicando melhorias...")
    
    # 1. Normaliza√ß√£o de termos
    print("   ‚úì Normalizando termos t√©cnicos...")
    for seg in segmentos:
        seg['text'] = normalizar_termos(seg['text'])
    
    # 2. Limpeza de v√≠cios de fala
    print(f"   ‚úì Limpando v√≠cios de fala (modo: {modo_limpeza})...")
    for seg in segmentos:
        seg['text'] = limpar_vicios_fala(seg['text'], modo_limpeza)
    
    # 3. Segmenta√ß√£o por t√≥picos
    print("   ‚úì Segmentando por t√≥picos...")
    segmentos = segmentar_por_topicos(segmentos, max_chars_bloco)
    
    # 4. P√≥s-corre√ß√£o com LLM (opcional)
    if usar_llm and llm_api_key:
        print("   ‚úì Aplicando corre√ß√£o sem√¢ntica com LLM...")
        for seg in segmentos:
            seg['text'] = corrigir_com_llm(seg['text'], llm_api_key)
    
    # Organiza por t√≥picos
    print("   ‚úì Organizando por t√≥picos...")
    transcricao_organizada = organizar_por_topicos(segmentos)
    
    # Salva resultado final
    nome_base = Path(caminho_arquivo_bruto).stem.replace('_transcricao_bruta', '')
    arquivo_final = f"{nome_base}_avancado.txt"
    
    # L√™ metadados do arquivo bruto
    metadados = ler_metadados_arquivo_bruto(caminho_arquivo_bruto)
    
    salvar_transcricao_organizada(arquivo_final, transcricao_organizada, {
        'arquivo': metadados.get('arquivo', os.path.basename(caminho_arquivo_bruto)),
        'modelo': metadados.get('modelo', 'N/A'),
        'modo_limpeza': modo_limpeza,
        'pyannote': metadados.get('pyannote', False),
        'llm': usar_llm
    })
    
    print("\n" + "="*70)
    print("‚úÖ ETAPA 2 CONCLU√çDA")
    print("="*70)
    print(f"üìÑ Arquivo final: {arquivo_final}")
    print(f"üìä Segmentos: {len(segmentos)}")
    print(f"üé§ Speakers: {len(set(s.get('speaker', 'Speaker 1') for s in segmentos))}")
    print(f"üìë T√≥picos: {len(transcricao_organizada)}")
    print("="*70)
    
    return {
        'arquivo_final': arquivo_final,
        'segmentos': segmentos,
        'organizada': transcricao_organizada
    }

def extrair_segmentos_do_arquivo_bruto(caminho_arquivo: str) -> List[Dict]:
    """
    Extrai segmentos de arquivo bruto gerado na etapa 1
    """
    segmentos = []
    
    with open(caminho_arquivo, 'r', encoding='utf-8') as f:
        linhas = f.readlines()
    
    timestamp_pattern = r'\[(\d+):(\d+):(\d+)\]'
    speaker_pattern = r'Speaker\s+(\d+)'
    
    segmento_atual = None
    
    for linha in linhas:
        linha = linha.strip()
        if not linha or linha.startswith('=') or linha.startswith('üìÅ') or linha.startswith('ü§ñ'):
            continue
        
        # Detecta timestamp e speaker
        match_timestamp = re.search(timestamp_pattern, linha)
        match_speaker = re.search(speaker_pattern, linha, re.IGNORECASE)
        
        if match_timestamp and match_speaker:
            # Salva segmento anterior
            if segmento_atual:
                segmentos.append(segmento_atual)
            
            # Cria novo segmento
            horas, minutos, segundos = map(int, match_timestamp.groups())
            timestamp_segundos = horas * 3600 + minutos * 60 + segundos
            speaker = f"Speaker {match_speaker.group(1)}"
            
            # Extrai texto
            texto = linha.split(':', 1)[-1].strip() if ':' in linha else ''
            
            segmento_atual = {
                'start': timestamp_segundos,
                'end': timestamp_segundos + 10,
                'speaker': speaker,
                'text': texto
            }
        elif segmento_atual and linha:
            # Continua texto
            if segmento_atual['text']:
                segmento_atual['text'] += ' ' + linha
            else:
                segmento_atual['text'] = linha
    
    # Adiciona √∫ltimo segmento
    if segmento_atual:
        segmentos.append(segmento_atual)
    
    # Ajusta timestamps
    for i, seg in enumerate(segmentos):
        if i > 0:
            seg['start'] = segmentos[i-1]['end']
        if i < len(segmentos) - 1:
            seg['end'] = seg['start'] + max(5, len(seg['text'].split()) * 0.5)
    
    return segmentos

def ler_metadados_arquivo_bruto(caminho_arquivo: str) -> Dict:
    """
    L√™ metadados do arquivo bruto
    """
    metadados = {}
    
    with open(caminho_arquivo, 'r', encoding='utf-8') as f:
        for linha in f:
            if 'üìÅ Arquivo:' in linha:
                metadados['arquivo'] = linha.split(':', 1)[-1].strip()
            elif 'ü§ñ Modelo:' in linha:
                metadados['modelo'] = linha.split(':', 1)[-1].strip()
            elif 'üé§ PyAnnote:' in linha:
                metadados['pyannote'] = 'Sim' in linha
    
    return metadados

# ============================================================================
# FUN√á√ÉO PRINCIPAL (CHAMA AS DUAS ETAPAS)
# ============================================================================

def transcrever_avancado(caminho_video: str,
                         modelo: str = "large-v3",
                         usar_pyannote: bool = True,
                         pyannote_token: Optional[str] = None,
                         modo_limpeza: str = "medio",
                         usar_llm: bool = False,
                         llm_api_key: Optional[str] = None,
                         max_chars_bloco: int = 600,
                         apenas_transcrever: bool = False,
                         apenas_corrigir: bool = False):
    """
    Fun√ß√£o principal: Executa as duas etapas em sequ√™ncia
    
    Args:
        caminho_video: Caminho do arquivo de v√≠deo OU arquivo bruto (se apenas_corrigir=True)
        modelo: Modelo Whisper
        usar_pyannote: Se True, usa PyAnnote para diariza√ß√£o
        pyannote_token: Token de autentica√ß√£o PyAnnote
        modo_limpeza: "leve", "medio" ou "agressivo"
        usar_llm: Se True, usa LLM para p√≥s-corre√ß√£o
        llm_api_key: API key para LLM
        max_chars_bloco: Tamanho m√°ximo de bloco antes de dividir
        apenas_transcrever: Se True, s√≥ faz etapa 1 (transcri√ß√£o)
        apenas_corrigir: Se True, s√≥ faz etapa 2 (corre√ß√£o) - caminho_video deve ser arquivo bruto
    """
    # Se apenas corrigir, pula direto para etapa 2
    if apenas_corrigir:
        return corrigir_e_organizar(
            caminho_video,
            modo_limpeza=modo_limpeza,
            usar_llm=usar_llm,
            llm_api_key=llm_api_key,
            max_chars_bloco=max_chars_bloco
        )
    
    # ETAPA 1: Transcri√ß√£o
    resultado_etapa1 = transcrever_apenas(
        caminho_video,
        modelo=modelo,
        usar_pyannote=usar_pyannote,
        pyannote_token=pyannote_token
    )
    
    if not resultado_etapa1:
        return None
    
    # Se apenas transcrever, para aqui
    if apenas_transcrever:
        return resultado_etapa1
    
    # ETAPA 2: Corre√ß√£o e organiza√ß√£o
    resultado_etapa2 = corrigir_e_organizar(
        resultado_etapa1['arquivo_bruto'],
        modo_limpeza=modo_limpeza,
        usar_llm=usar_llm,
        llm_api_key=llm_api_key,
        max_chars_bloco=max_chars_bloco
    )
    
    return resultado_etapa2

def organizar_por_topicos(segmentos: List[Dict]) -> Dict[str, List[Dict]]:
    """
    Organiza segmentos por t√≥picos
    """
    organizado = {}
    
    for seg in segmentos:
        topico = seg.get('topico', 'Geral')
        if topico not in organizado:
            organizado[topico] = []
        organizado[topico].append(seg)
    
    return organizado

def salvar_transcricao_organizada(arquivo: str, transcricao_organizada: Dict, metadados: Dict):
    """
    Salva transcri√ß√£o organizada por t√≥picos
    """
    with open(arquivo, 'w', encoding='utf-8') as f:
        f.write("="*70 + "\n")
        f.write("üöÄ TRANSCRI√á√ÉO AVAN√áADA - VERS√ÉO FINAL\n")
        f.write("="*70 + "\n\n")
        f.write(f"üìÅ Arquivo: {metadados['arquivo']}\n")
        f.write(f"ü§ñ Modelo: {metadados['modelo']}\n")
        f.write(f"üîß Modo limpeza: {metadados['modo_limpeza']}\n")
        f.write(f"üé§ PyAnnote: {'Sim' if metadados['pyannote'] else 'N√£o'}\n")
        f.write(f"ü§ñ LLM: {'Sim' if metadados['llm'] else 'N√£o'}\n")
        f.write("\n" + "="*70 + "\n")
        f.write("TRANSCRI√á√ÉO ORGANIZADA POR T√ìPICOS\n")
        f.write("="*70 + "\n\n")
        
        # Ordena t√≥picos por ordem de apari√ß√£o
        topicos_ordenados = sorted(transcricao_organizada.keys(), 
                                   key=lambda t: min(s['start'] for s in transcricao_organizada[t]))
        
        for topico in topicos_ordenados:
            segmentos = transcricao_organizada[topico]
            
            f.write("\n" + "="*70 + "\n")
            f.write(f"üìë {topico.upper()}\n")
            f.write("="*70 + "\n\n")
            
            speaker_anterior = None
            for seg in segmentos:
                if speaker_anterior and speaker_anterior != seg['speaker']:
                    f.write("\n")
                
                timestamp = formatar_timestamp(seg['start'])
                f.write(f"[{timestamp}] {seg['speaker']}:\n")
                f.write(f"{seg['text']}\n\n")
                
                speaker_anterior = seg['speaker']
            
            f.write("\n")

# ============================================================================
# MAIN
# ============================================================================

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("="*70)
        print("üöÄ WHISPER AVAN√áADO - VERS√ÉO FINAL (POR ETAPAS)")
        print("="*70)
        print("\nUso: python whisper_avancado.py <arquivo> [op√ß√µes]")
        print("\nModos de execu√ß√£o:")
        print("  (padr√£o)              - Executa ETAPA 1 (transcreve) + ETAPA 2 (corrige)")
        print("  --apenas-transcrever  - S√≥ executa ETAPA 1 (transcreve e salva bruto)")
        print("  --corrigir            - S√≥ executa ETAPA 2 (corrige arquivo bruto)")
        print("\nOp√ß√µes:")
        print("  [modelo]              - tiny, base, small, medium, large, large-v3 (padr√£o: large-v3)")
        print("  [modo_limpeza]        - leve, medio, agressivo (padr√£o: medio)")
        print("  --sem-pyannote        - N√£o usa PyAnnote (diariza√ß√£o simplificada)")
        print("  --pyannote-token TOKEN - Token de autentica√ß√£o PyAnnote")
        print("  --llm                 - Usa LLM para p√≥s-corre√ß√£o (requer --llm-key)")
        print("  --llm-key KEY         - API key para LLM (OpenAI)")
        print("\nExemplos:")
        print('  # Executa tudo (transcreve + corrige)')
        print('  python whisper_avancado.py "video.mp4"')
        print('')
        print('  # S√≥ transcreve (mais r√°pido)')
        print('  python whisper_avancado.py "video.mp4" --apenas-transcrever')
        print('')
        print('  # S√≥ corrige arquivo bruto j√° gerado')
        print('  python whisper_avancado.py "video_transcricao_bruta.txt" --corrigir')
        print('')
        print('  # Com op√ß√µes')
        print('  python whisper_avancado.py "video.mp4" large-v3 medio --llm --llm-key sk-...')
        print("\nMelhorias implementadas:")
        print("  ‚úì Diariza√ß√£o separada (PyAnnote)")
        print("  ‚úì Segmenta√ß√£o por t√≥picos")
        print("  ‚úì Limpeza de v√≠cios de fala")
        print("  ‚úì Normaliza√ß√£o robusta de termos")
        print("  ‚úì P√≥s-corre√ß√£o sem√¢ntica (LLM opcional)")
        print("  ‚úì Organiza√ß√£o em blocos tem√°ticos")
        print("\nüí° Dica: Use --apenas-transcrever para transcrever mais r√°pido,")
        print("   depois use --corrigir para aplicar melhorias quando quiser.")
        sys.exit(1)
    
    caminho = sys.argv[1].strip('"\'')
    modelo = "large-v3"
    modo_limpeza = "medio"
    usar_pyannote = True
    pyannote_token = None
    usar_llm = False
    llm_api_key = None
    apenas_transcrever = False
    apenas_corrigir = False
    
    # Processa argumentos
    i = 2
    while i < len(sys.argv):
        arg = sys.argv[i]
        if arg in ['tiny', 'base', 'small', 'medium', 'large', 'large-v3']:
            modelo = arg
        elif arg in ['leve', 'medio', 'agressivo']:
            modo_limpeza = arg
        elif arg == '--sem-pyannote':
            usar_pyannote = False
        elif arg == '--pyannote-token' and i + 1 < len(sys.argv):
            pyannote_token = sys.argv[i + 1]
            i += 1
        elif arg == '--llm':
            usar_llm = True
        elif arg == '--llm-key' and i + 1 < len(sys.argv):
            llm_api_key = sys.argv[i + 1]
            i += 1
        elif arg == '--apenas-transcrever':
            apenas_transcrever = True
        elif arg == '--corrigir':
            apenas_corrigir = True
        i += 1
    
    transcrever_avancado(
        caminho,
        modelo=modelo,
        usar_pyannote=usar_pyannote,
        pyannote_token=pyannote_token,
        modo_limpeza=modo_limpeza,
        usar_llm=usar_llm,
        llm_api_key=llm_api_key,
        apenas_transcrever=apenas_transcrever,
        apenas_corrigir=apenas_corrigir
    )

